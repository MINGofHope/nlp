{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfW4Kav7g3JBWXH7kSBBsh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanmingl/NaturalLanguageProcessing/blob/master/Transformers_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Copyright 2019 The TensorFlow Authors."
      ],
      "metadata": {
        "id": "gopLo-spDJJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Chatbot\n",
        "\n"
      ],
      "metadata": {
        "id": "v0bDb3OQGPnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Import Packages"
      ],
      "metadata": {
        "id": "I0w_xZakGVYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tensorflow, load it, and set the random seed\n",
        "# !pip install tensorflow==2.9.1\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# import embedded dataset\n",
        "# !pip install tensorflow-datasets==4.6.0\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# import other pacakages\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9Yz7JqDUHB9R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU /TPU initialization\n",
        "On Google colab, select  `TPU` or `GPU` hardware accelerator"
      ],
      "metadata": {
        "id": "NKdke9Ye9hu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "S7hmAhduOq7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "# Max length of a sentence whether for question or answer\n",
        "MAX_LENGTH = 40"
      ],
      "metadata": {
        "id": "UBUYQzdUOval"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset\n",
        "Cornell Movie-Dialogs Corpus\n",
        "- more than 220 thousands conversational exchanges\n",
        "- between more then 10k pairs of characters\n",
        "\n",
        "**movie_conversation.txt** contains list of conversation IDs and **movie_lines.text** contains the  text associated with each conversation ID.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5EENQCuIYLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset and define the file path\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'cornell_movie_dialogs.zip',\n",
        "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
        "    extract = True # download as an archive\n",
        ")"
      ],
      "metadata": {
        "id": "tF9whNexKD9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4f2f63-78bc-4cf7-e4a8-e5dc8007eafe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "9916637/9916637 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t9325NJeMGe_",
        "outputId": "4a174dc6-f10a-40e9-9018-fb0cfc083a9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/cornell_movie_dialogs.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = os.path.join(os.path.dirname(path_to_zip), 'cornell movie-dialogs corpus')\n",
        "path_to_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YZ_zD6o_MJYg",
        "outputId": "40d779e1-807a-4627-aca6-331c4cdbddf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/cornell movie-dialogs corpus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
        "path_to_movie_conversations = os.path.join(path_to_dataset, 'movie_conversations.txt')\n",
        "path_to_movie_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oj_lyJzFMlIC",
        "outputId": "b549c689-3bf6-4c0b-f700-fe83e7cd237c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/cornell movie-dialogs corpus/movie_lines.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess data\n",
        "For simplificity and fastness, we limit the maximum number fo trainning sampels to 25000, and the maximum length of the sentence to be 40.\n",
        "\n",
        "We preprocess the dataset in the following orders:\n",
        "- Extract `MAX_SAMPLES` conversation pairs into list of `question` and `answers`.\n",
        "- Preprocess each sentence by removing special characters in each sentence.\n",
        "- Build tokenizer(map text to ID and ID to text)\n",
        "- Tokenize each sentence and add `START_TOKEN` and `END_TOKEN` to indicate the start and end of the sentence.\n",
        "- Filter out sentence that has more than `MAX_LENGTH` tokens.\n",
        "- Pad tokenized sentences to `MAX_LENGTH`."
      ],
      "metadata": {
        "id": "Vo8GftOGNDP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract question-answer pairs and remove the special characters in each sentence"
      ],
      "metadata": {
        "id": "Zl6m0LRaGvdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_sentence(sentence):\n",
        "#   # lowercase all words and remove the spaces at beginning and ending\n",
        "#   sentence = sentence.lower().strip()\n",
        "#   # put a space between a word and the punctuation following,\n",
        "#   # e.g. 'he is a boy.' --> 'he is a boy .'\n",
        "#   sentence = re.sub(r'([?!.,])', r' \\1 ', sentence)\n",
        "#   # transform multi spaces into one space, '  ' --> ' '\n",
        "#   sentence = re.sub(r\"[' ']+\", ' ', sentence)\n",
        "#   # removing contractions\n",
        "#   sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
        "#   sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "#   sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
        "#   sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "#   sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
        "#   sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
        "#   sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
        "#   sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
        "#   sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
        "#   sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
        "#   sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "#   sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
        "#   sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "#   sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "#   sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
        "#   sentence = re.sub(r\"n't\", \" not\", sentence)\n",
        "#   sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
        "#   sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
        "#   # replace everthing with space except (a-z, A-Z, '.?!,')\n",
        "#   sentence = re.sub(r'[^a-zA-Z?.!,]+', ' ', sentence)\n",
        "#   # remove the space at the begining and ending again\n",
        "#   setence = sentence.strip()\n",
        "#   return sentence\n",
        "\n",
        "# def load_conversations():\n",
        "#   # dictionary of line to text\n",
        "#   id2line = {}\n",
        "#   # return a list of lines\n",
        "#   # e.g. ['Hello!\\n', 'This file is for testing purposes.\\n', 'Good Luck!']\n",
        "#   with open(path_to_movie_lines, errors='ignore') as file:\n",
        "#     lines = file.readlines()\n",
        "#   # get line ID and text to id2line for each line\n",
        "#   # e.g. just one line\n",
        "#   # L900 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ As in…  --> {L900:AS in...}\n",
        "#   for line in lines:\n",
        "#     parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "#     id2line[parts[0]] = parts[4]\n",
        "#   # get the question and answer using the lineID in the movie_conversations.txt\n",
        "#   # and id2line, and put them into inputs and outputs respectively\n",
        "#   inputs, outputs = [], []\n",
        "#   with open(path_to_movie_conversations, 'r') as file:\n",
        "#     lines = file.readlines()\n",
        "#   # e.g. u0 +++$+++ u2 +++$+++ m0 +++$+++ [‘L198’, ‘L199’]\n",
        "#   for line in lines:\n",
        "#     parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "#     # to get ['L198', 'L199']\n",
        "#     conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "#     # The former is the inputs, the latter is the outputs. > PUZZLE\n",
        "#     for i in range(len(conversation)-1):\n",
        "#       inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "#       outputs.append(preprocess_sentence(id2line[conversation[i+1]]))\n",
        "#       if len(inputs) >= MAX_SAMPLES:\n",
        "#         return inputs, outputs\n",
        "#   return inputs, outputs\n",
        "\n",
        "# questions, answers = load_conversations()"
      ],
      "metadata": {
        "id": "Wf0UliCZRAp-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    # removing contractions\n",
        "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
        "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
        "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
        "    sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
        "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
        "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
        "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
        "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
        "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
        "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
        "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def load_conversations():\n",
        "    # dictionary of line id to text\n",
        "    id2line = {}\n",
        "    with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
        "        lines = file.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
        "        id2line[parts[0]] = parts[4]\n",
        "\n",
        "    inputs, outputs = [], []\n",
        "    with open(path_to_movie_conversations, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
        "        # get conversation in a list of line ID\n",
        "        conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
        "        for i in range(len(conversation) - 1):\n",
        "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "            if len(inputs) >= MAX_SAMPLES:\n",
        "                return inputs, outputs\n",
        "    return inputs, outputs\n",
        "questions, answers = load_conversations()"
      ],
      "metadata": {
        "id": "zNiGfs6ZZWFl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'sample quesiton: {questions[20]}')\n",
        "print(f'sample answer: {answers[20]}')"
      ],
      "metadata": {
        "id": "s1YGB8WfuTz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468321be-420e-4ec5-bdb1-f75ea17d3bf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample quesiton: i really , really , really wanna go , but i cannot . not unless my sister goes .\n",
            "sample answer: i am working on it . but she does not seem to be going for him .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Tokenizer"
      ],
      "metadata": {
        "id": "4Tk1NhpxD7zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build tokenizer from corpus\n",
        "# input the list of question and answer strings, also the vocab size, encoding to [1, ... vocab_size)\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size = 2**13  # approximate size of target vocabulary\n",
        ")"
      ],
      "metadata": {
        "id": "8TsCFqXsHM2L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tokenized sample question {tokenizer.encode(questions[20])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uxcZ8AnHuR6",
        "outputId": "54f8a144-d9f7-40c3-e83c-2522eed8206e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sample question [4, 271, 3, 271, 3, 141, 385, 173, 3, 40, 4, 611, 2, 11, 864, 30, 2021, 3086, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the vocabulary. Decode produces ints [1, vocab_size).\n",
        "tokenizer.vocab_size  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFY3xJFhRqQA",
        "outputId": "15a78cfe-9640-48c8-9fab-d1733937320f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8277"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize, filter and pad sentences"
      ],
      "metadata": {
        "id": "NuqgURdtLvzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define START_TOKEN and END_TOKEN\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize the sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen = MAX_LENGTH, padding='post'\n",
        "  )\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
        "  )\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers) \n",
        "\n",
        "# Define VOCAD_SIZE for padded sentences\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2  # for start and end token"
      ],
      "metadata": {
        "id": "qvp8jlTGL53D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocab size: {VOCAB_SIZE}\")\n",
        "print(f\"Number of samples: {len(questions)}\")"
      ],
      "metadata": {
        "id": "hK3bvBxnQ3lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c30bad-4b2f-4fd6-c197-6b51965d4401"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 8279\n",
            "Number of samples: 44131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create `tf.data.DataSet`"
      ],
      "metadata": {
        "id": "DQ9cgA0NfmNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "\n",
        "# decode_inputs: remove the END_TOKEN\n",
        "# outputs: remove the START_TOKEN\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (\n",
        "      {'inputs': questions, 'decode_inputs': questions[:, :-1]},\n",
        "      {'outputs': answers[:, 1:]}\n",
        "  )\n",
        ")\n",
        "\n",
        "# Add dataset to cache\n",
        "dataset = dataset.cache()\n",
        "# Shuffle dataset for better training accuracy\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "# Get batches of the dataset\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "# Prefetch next batch during the trainning of this batch to accelerate\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "AGjh-KZ-gdAE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjgVtn7LgiF7",
        "outputId": "f4db1362-55eb-473d-e217-1ff9443336dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=({'inputs': TensorSpec(shape=(None, 40), dtype=tf.int32, name=None), 'decode_inputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention\n",
        "#### Scaled dot product attention"
      ],
      "metadata": {
        "id": "qcEoo7l2lcMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # QK^T\n",
        "  matmul = tf.matmul(query, key, transpose_b=True)\n",
        "  # (QK^T) / sqrt(d_k)\n",
        "  d_k = tf.cast(tf.shape(key), dtype=tf.float32)\n",
        "  logits = matmul / tf.math.sqrt(d_k)\n",
        "  \n",
        "  # mask \n",
        "\n",
        "\n",
        "\n",
        "  # softmax on the logits\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)  # why on -1 axis and softmax\n",
        "  # multiply V\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ],
      "metadata": {
        "id": "rT4mQPd3ot8I"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Head Attention\n"
      ],
      "metadata": {
        "id": "l_5sVrpgrBNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "list = np.array([[1,2,3], [3,4,5]])\n",
        "\n",
        "list.shape[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4UNCG0trGrS",
        "outputId": "c44622dc-03d3-4395-811f-4b47ec0ca3d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer\n"
      ],
      "metadata": {
        "id": "2zcWjsNS0hQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking"
      ],
      "metadata": {
        "id": "qoqhYoeEO7Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence_length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "PK1pavsjQq8R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_padding_mask(tf.constant([[1,2,0,3,0], [0,0,0,4,5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pybi_LogRbws",
        "outputId": "acd3f56c-50b9-40d7-cd8d-587ab9c4d133"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "V9Ydo5RCRxkL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1,20,0,4,5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb4BRG3ShEYS",
        "outputId": "abb79407-60d5-446e-b8ec-1b67b28428b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Positional encoding"
      ],
      "metadata": {
        "id": "VrRL5cMcRmKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layer.Layer):\n",
        "  def __init__(self, position, d_model, **kwargs) -> None:\n",
        "     super(PositionalEncoding, self).__init__(**kwargs)\n",
        "     self.position = position\n",
        "     self.d_model = d_model\n",
        "     self.pos_encoding = self.postional_encoding(position, d_model)\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super(PositionalEncoding, self).get_config()\n",
        "    config.update(\n",
        "        {\n",
        "            'position': self.position,\n",
        "            'd_model': self.d_model,\n",
        "        }\n",
        "    )\n",
        "    return config\n",
        "  \n",
        "  def"
      ],
      "metadata": {
        "id": "HAb896UIicBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}