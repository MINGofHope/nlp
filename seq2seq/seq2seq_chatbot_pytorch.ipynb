{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "A sequence to sequence model that incorporates attention mechanism for response generation for chatbot.\n",
    "We adopt code from the [Neural Machin Translation Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-decoder) using Pytorch.\n",
    "Changes mainly focus on dataset, performance analysis for further usage.\n",
    "We suggest that you gain the conceptual knowledge for seq2seq model and its attention mechanism through papers and above-mentioned tutorials firstly, then zoom into the code implementation using Pytorch. Make your hand dirty is always the key to coding. Make sure the steps and purpose for each step before you write down the code, and know how the data flows and their dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('hello, world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}