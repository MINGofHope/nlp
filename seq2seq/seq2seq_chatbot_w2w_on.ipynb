{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yanmingl/NaturalLanguageProcessing/blob/master/seq2seq_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.13 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f83c6d50081b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxcOYvrNVmB4",
    "outputId": "66a75be3-566f-406e-b155-11e58bc3ec39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading http://pypi.doubanio.com/packages/bf/4a/5c86ed8b245aa48f9f819b13a0a9039e9126ba19fdd0c7e0b8026c12315a/tensorflow-1.14.0-cp36-cp36m-win_amd64.whl (68.3 MB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading http://pypi.doubanio.com/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading http://pypi.doubanio.com/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading http://pypi.doubanio.com/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading http://pypi.doubanio.com/packages/30/98/baa62c0b771cb20b0381896fb61926d9bec783fb446eaa53efd4e5c70e3b/grpcio-1.48.2-cp36-cp36m-win_amd64.whl (3.6 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading http://pypi.doubanio.com/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorflow==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorflow==1.14.0) (3.19.6)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading http://pypi.doubanio.com/packages/f0/db/2a9ea49cd8bdde87a85262e517563d42b9e5b760473597b9da511fcbd54d/wrapt-1.14.1-cp36-cp36m-win_amd64.whl (36 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading http://pypi.doubanio.com/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading http://pypi.doubanio.com/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorflow==1.14.0) (0.37.1)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading http://pypi.doubanio.com/packages/2c/39/ba081c6f7837366a39c9286fa1bc9dbf217249df80e133f25c62b05d1a53/absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorflow==1.14.0) (1.19.5)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading http://pypi.doubanio.com/packages/5f/1c/b59500a88c5c3d9d601c5ca62b9df5e0964764472faed82a182958a922c5/gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading http://pypi.doubanio.com/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting h5py\n",
      "  Downloading http://pypi.doubanio.com/packages/35/39/ceabe8fa912cb27ec9a0064fe01c1fde2f8b43e9f7e506207db0a0dcea0a/h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in d:\\miniconda3\\envs\\py36\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.8)\n",
      "Collecting cached-property\n",
      "  Downloading http://pypi.doubanio.com/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=a44e298d85229150a3503db243069ada28b894ab4d13329c40377b43a7677548\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\ca\\f2\\60\\0b9724e1c596aac6849f5240074453c349c267652d0a9a6428\n",
      "Successfully built termcolor\n",
      "Installing collected packages: cached-property, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.4.0\n",
      "    Uninstalling tensorflow-1.4.0:\n",
      "      Successfully uninstalled tensorflow-1.4.0\n",
      "Successfully installed absl-py-1.3.0 astor-0.8.1 cached-property-1.5.2 gast-0.5.3 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, re\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "sIitZHrZVmB9"
   },
   "outputs": [],
   "source": [
    "MAX_VOC_PER_LINE = 40\n",
    "\n",
    "def load_sentences(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding=\"ISO-8859-1\") as f1, \\\n",
    "         open(output_path, 'r', encoding=\"ISO-8859-1\") as f2:\n",
    "        input_data, output_data = f1.read().encode('ascii', 'ignore').decode('UTF-8'), \\\n",
    "                                  f2.read().encode('ascii', 'ignore').decode('UTF-8')\n",
    "        # input_data = re.sub('[^a-z\\n]+', ' ', input_data)\n",
    "        # output_data = re.sub('[^a-z\\n]+', ' ', output_data)\n",
    "        input_seq, output_seq = [], []\n",
    "        for i, line in enumerate(input_data.split('\\n')):\n",
    "            input_voc_list_per_line = line.split(' ')\n",
    "            input_length_voc_per_line = len(input_voc_list_per_line)\n",
    "            if input_length_voc_per_line > MAX_VOC_PER_LINE:\n",
    "              continue\n",
    "            output_data_per_line = output_data.split('\\n')\n",
    "            current_output_line = output_data_per_line[i]\n",
    "            current_output_length_line = len(current_output_line.split(' '))\n",
    "            if current_output_length_line > MAX_VOC_PER_LINE:\n",
    "              continue\n",
    "            input_seq.append(line)\n",
    "            output_seq.append(current_output_line)\n",
    "\n",
    "    return input_seq, output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7RaNMvvUhBN",
    "outputId": "1cde4369-7010-4283-b48d-e4320d470bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .', 'well , i thought we would start with pronunciation , if that is okay with you .', 'not the hacking and gagging and spitting part . please .', 'you are asking me out . that is so cute . that is your name again ?', 'no , no , it is my fault we did not have a proper introduction'] \n",
      " 45609\n",
      "['well , i thought we would start with pronunciation , if that is okay with you .', 'not the hacking and gagging and spitting part . please .', 'okay . . . then how about we try out some french cuisine . saturday ? night ?', 'forget it .', 'cameron .'] \n",
      " 45609\n"
     ]
    }
   ],
   "source": [
    "input_sentences, output_sentences = load_sentences('data/words_input.txt', 'data/words_output.txt')  \n",
    "print(input_sentences[:5], '\\n', len(input_sentences))\n",
    "print(output_sentences[:5], '\\n', len(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RKzlLMIHVmB-"
   },
   "outputs": [],
   "source": [
    "def extract_vocab(data):\n",
    "    special_vocs = ['<PAD>', '<UNK>', '<GO>',  '<EOS>']\n",
    "    set_vocs = set([voc for line in data for voc in line.split(' ')])\n",
    "    all_vocs = special_vocs + list(set_vocs)\n",
    "    int_to_voc = {word_i: word for word_i, word in enumerate(all_vocs)}\n",
    "    voc_to_int = {word: word_i for word_i, word in int_to_voc.items()}\n",
    "    return int_to_voc, voc_to_int\n",
    "\n",
    "\n",
    "input_int_to_voc, input_voc_to_int = extract_vocab(input_sentences)\n",
    "output_int_to_voc, output_voc_to_int = extract_vocab(output_sentences)\n",
    "[['yes', ''], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9YyUI1KmNVc",
    "outputId": "32e37019-8f50-4d59-f1c3-8b5d941039f6"
   },
   "outputs": [],
   "source": [
    "# print(input_int_to_voc)\n",
    "# print(len(input_int_to_voc))\n",
    "# print(output_int_to_voc)\n",
    "# print(len(output_int_to_voc))\n",
    "# print(input_voc_to_int)\n",
    "\n",
    "# Here is the puzzle. The number of tokenized word is different with the one of \n",
    "# transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "XAhCn8_UVmCB",
    "outputId": "891f89d3-0a67-49be-82e2-879cef84a7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16917\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCS = 3\n",
    "RNN_STATE_DIM = 512\n",
    "RNN_NUM_LAYERS = 2\n",
    "ENCODER_EMBEDDING_DIM = DECODER_EMBEDDING_DIM = 64\n",
    " \n",
    "BATCH_SIZE = int(64)\n",
    "LEARNING_RATE = 0.0003\n",
    " \n",
    "INPUT_NUM_VOCAB = len(input_voc_to_int)\n",
    "OUTPUT_NUM_VOCAB = len(output_voc_to_int)\n",
    "print(OUTPUT_NUM_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "id": "yKEIBCo-VmCC"
   },
   "outputs": [],
   "source": [
    "# Encoder placeholders\n",
    "encoder_input_seq = tf.placeholder(\n",
    "    tf.int32, \n",
    "    [None, None],  # batch_size * seq_length\n",
    "    name='encoder_input_seq'\n",
    ")\n",
    "\n",
    "encoder_seq_len = tf.placeholder(\n",
    "    tf.int32, \n",
    "    (None,),   # shape is dynamic bca th length of a sequence can change\n",
    "    name='encoder_seq_len'\n",
    ")\n",
    " \n",
    "# Decoder placeholders\n",
    "decoder_output_seq = tf.placeholder( \n",
    "    tf.int32, \n",
    "    [None, None],\n",
    "    name='decoder_output_seq'\n",
    ")\n",
    "\n",
    "decoder_seq_len = tf.placeholder(\n",
    "    tf.int32,\n",
    "    (None,), \n",
    "    name='decoder_seq_len'\n",
    ")\n",
    "\n",
    "max_decoder_seq_len = tf.reduce_max(  \n",
    "    decoder_seq_len,   # maximum length of a decoder sequence for a batch\n",
    "    name='max_decoder_seq_len'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "QGzM3RfvVmCE"
   },
   "outputs": [],
   "source": [
    "def make_cell(state_dim):\n",
    "    lstm_initializer = tf.random_uniform_initializer(-0.1, 0.1)\n",
    "    return tf.contrib.rnn.LSTMCell(state_dim, initializer=lstm_initializer)\n",
    " \n",
    "def make_multi_cell(state_dim, num_layers):\n",
    "    cells = [make_cell(state_dim) for _ in range(num_layers)]\n",
    "    return tf.contrib.rnn.MultiRNNCell(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOAWbAElVmCE",
    "outputId": "fbcbc2a7-7ad5-4d5d-900f-936cae503878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-9-b0e2ecdc0d3e>:3: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-b0e2ecdc0d3e>:7: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-10-daed38c1850a>:18: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D92C178208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D92C178208>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D92C178208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D92C178208>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D92C3F58D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D92C3F58D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D92C3F58D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D92C3F58D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D954153B00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D954153B00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D954153B00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D954153B00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Encoder embedding\n",
    " \n",
    "encoder_input_embedded = tf.contrib.layers.embed_sequence(\n",
    "    encoder_input_seq,     \n",
    "    INPUT_NUM_VOCAB,        \n",
    "    ENCODER_EMBEDDING_DIM  \n",
    ")\n",
    " \n",
    " \n",
    "# Encodering output\n",
    " \n",
    "encoder_multi_cell = make_multi_cell(RNN_STATE_DIM, RNN_NUM_LAYERS)\n",
    " \n",
    "encoder_output, encoder_state = tf.nn.dynamic_rnn(\n",
    "    encoder_multi_cell, \n",
    "    encoder_input_embedded, \n",
    "    sequence_length=encoder_seq_len, \n",
    "    dtype=tf.float32\n",
    ")\n",
    " \n",
    "del(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "2WVtIq8EVmCF"
   },
   "outputs": [],
   "source": [
    "decoder_raw_seq = decoder_output_seq[:, :-1]  \n",
    "go_prefixes = tf.fill([BATCH_SIZE, 1], output_voc_to_int['<GO>'])  \n",
    "decoder_input_seq = tf.concat([go_prefixes, decoder_raw_seq], 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H9X6Pr69VmCG"
   },
   "outputs": [],
   "source": [
    "decoder_embedding = tf.Variable(tf.random_uniform([OUTPUT_NUM_VOCAB, \n",
    "                                                   DECODER_EMBEDDING_DIM]))\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(decoder_embedding, \n",
    "                                                decoder_input_seq)\n",
    "\n",
    "decoder_multi_cell = make_multi_cell(RNN_STATE_DIM, RNN_NUM_LAYERS)\n",
    " \n",
    "output_layer_kernel_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "output_layer = Dense(\n",
    "    OUTPUT_NUM_VOCAB,\n",
    "    kernel_initializer = output_layer_kernel_initializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hzk43PUlVmCG",
    "outputId": "d1fc6ad2-4573-4be9-9604-82f5b133de94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"decode\"):\n",
    " \n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        inputs=decoder_input_embedded,\n",
    "        sequence_length=decoder_seq_len,\n",
    "        time_major=False\n",
    "    )\n",
    " \n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_multi_cell,\n",
    "        training_helper,\n",
    "        encoder_state,\n",
    "        output_layer\n",
    "    ) \n",
    " \n",
    "    training_decoder_output_seq, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        training_decoder, \n",
    "        impute_finished=True, \n",
    "        maximum_iterations=max_decoder_seq_len\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Tm2WTYnlVmCH",
    "outputId": "675eb8ad-333f-4f14-e85e-e3ad5c495f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001D953D31CC0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D318D0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001D953D317B8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D953D31588>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"decode\", reuse=True):\n",
    "    start_tokens = tf.tile(\n",
    "        tf.constant([output_voc_to_int['<GO>']], \n",
    "                    dtype=tf.int32), \n",
    "        [BATCH_SIZE], \n",
    "        name='start_tokens')\n",
    " \n",
    "    # Helper for the inference process.\n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "        embedding=decoder_embedding,\n",
    "        start_tokens=start_tokens,\n",
    "        end_token=output_voc_to_int['<EOS>']\n",
    "    )\n",
    " \n",
    "    # Basic decoder\n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_multi_cell,\n",
    "        inference_helper,\n",
    "        encoder_state,\n",
    "        output_layer\n",
    "    )\n",
    " \n",
    "    # Perform dynamic decoding using the decoder\n",
    "    inference_decoder_output_seq, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        inference_decoder,\n",
    "        impute_finished=True,\n",
    "        maximum_iterations=max_decoder_seq_len\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "YTti4wQjVmCI"
   },
   "outputs": [],
   "source": [
    "# rename the tensor for our convenience\n",
    "training_logits = tf.identity(training_decoder_output_seq.rnn_output, name='logits')\n",
    "inference_logits = tf.identity(inference_decoder_output_seq.sample_id, name='predictions')\n",
    " \n",
    "# Create the weights for sequence_loss\n",
    "masks = tf.sequence_mask(\n",
    "    decoder_seq_len, \n",
    "    max_decoder_seq_len, \n",
    "    dtype=tf.float32, \n",
    "    name='masks'\n",
    ")\n",
    " \n",
    "cost = tf.contrib.seq2seq.sequence_loss(\n",
    "    training_logits,\n",
    "    decoder_output_seq,\n",
    "    masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "__c0YVTDVmCI"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    " \n",
    "gradients = optimizer.compute_gradients(cost)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var)\n",
    "                        for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "id": "dMal2xbxVmCJ"
   },
   "outputs": [],
   "source": [
    "def pad(xs, size, pad):\n",
    "    return xs + [pad] * (size - len(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "EEhdzpYvVmCK",
    "outputId": "e86821a6-8736-499b-af65-80d8c86faa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6146, 8645, 1109, 8988, 16414, 8521, 6953, 7090, 3066, 4958, 416, 4971, 2213, 573, 5796, 14533, 3641, 12403, 15768, 6559, 12131, 16005, 2997, 13803, 2997], [14709, 11291, 6929, 14823, 8645, 12420, 15274, 6249, 7743, 11291, 16115, 5175, 368, 12318, 6249, 15408, 2997], [9361, 12131, 9597, 3066, 3576, 3066, 6598, 2600, 2997, 11540, 2997], [15408, 4971, 15078, 14784, 10919, 2997, 5175, 368, 11969, 3501, 2997, 5175, 368, 9910, 4169, 13803, 8521], [11541, 11291, 11541, 11291, 324, 368, 935, 9413, 8645, 11204, 9361, 16564, 16764, 15448, 16508]]\n",
      "[[14755, 11330, 7011, 14871, 8687, 12445, 15305, 6309, 7812, 11330, 16144, 5240, 361, 12351, 6309, 15435, 3052, 3], [9382, 12171, 9609, 3115, 3625, 3115, 6668, 2645, 3052, 11584, 3052, 3], [12351, 3052, 3052, 3052, 7807, 10622, 9074, 8687, 2768, 10946, 4492, 11952, 4510, 3052, 8785, 8563, 12386, 8563, 3], [5039, 315, 3052, 3], [1597, 3052, 3]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must have the same first dimension, got logits shape [1984,16917] and labels shape [2560]\n\t [[node sequence_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-15-e9174850e686>:16) ]]\n\nOriginal stack trace for 'sequence_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n  File \"d:\\miniconda3\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e9174850e686>\", line 16, in <module>\n    masks\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\loss.py\", line 113, in sequence_loss\n    labels=targets, logits=logits_flat)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3342, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11920, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [1984,16917] and labels shape [2560]\n\t [[{{node sequence_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-95763530d2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mencoder_seq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mdecoder_output_seq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdecoder_seq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput_lengths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             }\n\u001b[0;32m     53\u001b[0m         )\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [1984,16917] and labels shape [2560]\n\t [[node sequence_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-15-e9174850e686>:16) ]]\n\nOriginal stack trace for 'sequence_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n  File \"d:\\miniconda3\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e9174850e686>\", line 16, in <module>\n    masks\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\loss.py\", line 113, in sequence_loss\n    labels=targets, logits=logits_flat)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3342, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11920, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"d:\\miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "input_seq_int = [\n",
    "    [input_voc_to_int.get(voc, input_voc_to_int['<UNK>']) \n",
    "        for voc in line.split(' ')]  \n",
    "    for line in input_sentences  \n",
    "]\n",
    " \n",
    "output_seq_int = [\n",
    "    [output_voc_to_int.get(voc, output_voc_to_int['<UNK>']) \n",
    "        for voc in line.split(' ')] + [output_voc_to_int['<EOS>']]  \n",
    "    for line in output_sentences  \n",
    "]\n",
    "\n",
    "# print(output_voc_to_int['<EOS>'])\n",
    "print(input_seq_int[:5])\n",
    "print(output_seq_int[:5])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()  \n",
    " \n",
    "for epoch in range(NUM_EPOCS + 1):  \n",
    "    for batch_idx in range(len(input_seq_int) // BATCH_SIZE): \n",
    "        \n",
    "        input_batch, input_lengths, output_batch, output_lengths = [], [], [], []\n",
    "        for sentence in input_seq_int[batch_idx:batch_idx + BATCH_SIZE]:\n",
    "           \n",
    "            \n",
    "            padded_voc_sent = pad(sentence, MAX_VOC_PER_LINE, input_voc_to_int['<PAD>'])\n",
    "            # print(input_voc_to_int['<PAD>'])\n",
    "            input_batch.append(padded_voc_sent)\n",
    "            input_lengths.append(len(sentence))\n",
    "            # print(padded_voc_sent)\n",
    "            # break\n",
    "        for sentence in output_seq_int[batch_idx:batch_idx + BATCH_SIZE]:\n",
    "            padded_voc_sent = pad(sentence, MAX_VOC_PER_LINE, output_voc_to_int['<PAD>'])\n",
    "            output_batch.append(padded_voc_sent)\n",
    "\n",
    "            output_lengths.append(len(sentence))\n",
    "\n",
    "            # print(output_voc_to_int['<PAD>'])\n",
    "            # print(padded_voc_sent)\n",
    "            # break\n",
    "            \n",
    "        # break\n",
    "        _, cost_val = sess.run( \n",
    "            [train_op, cost],\n",
    "            feed_dict={\n",
    "                encoder_input_seq: input_batch,\n",
    "                encoder_seq_len: input_lengths,\n",
    "                decoder_output_seq: output_batch,\n",
    "                decoder_seq_len: output_lengths,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if batch_idx % 629 == 0:\n",
    "            print('Epcoh {}. Batch {}/{}. Cost {}'.format(epoch, batch_idx, len(input_sentences) // BATCH_SIZE, cost_val))\n",
    "\n",
    "    # break\n",
    "    saver.save(sess, 'model.ckpt')   \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSQg1g_TbVBM"
   },
   "outputs": [],
   "source": [
    "for batch_idx in range(len(input_sentences) // BATCH_SIZE): \n",
    "  print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tefSsBcQVmCL"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()    \n",
    "saver.restore(sess, 'model.ckpt')\n",
    "\n",
    "example_input_sent = \"do you want to play games\"\n",
    "example_input_symb = [input_voc_to_int[voc] for voc in example_input_sent]\n",
    "example_input_batch = [pad(example_input_symb, MAX_CHAR_PER_LINE, input_voc_to_int['<PAD>'])] * BATCH_SIZE\n",
    "example_input_lengths = [len(example_input_sent)] * BATCH_SIZE\n",
    "\n",
    "output_ints = sess.run(inference_logits, feed_dict={\n",
    "    encoder_input_seq: example_input_batch,\n",
    "    encoder_seq_len: example_input_lengths,\n",
    "    decoder_seq_len: example_input_lengths\n",
    "})[0]\n",
    "\n",
    "output_str = ''.join([output_int_to_voc[i] for i in output_ints])\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbwsnaKWnZBk"
   },
   "outputs": [],
   "source": [
    "# Play an audio beep. Any audio URL will do.\n",
    "from google.colab import output\n",
    "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e719f66e745035044bf762632a005990aae7f3087f797f95d5c170998faa5492"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
